# Qwen2.5-VL FastAPI Inference Service

## –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞

–≠—Ç–æ—Ç —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π —Å–µ—Ä–≤–∏—Å –Ω–∞ –±–∞–∑–µ **FastAPI** –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª—å—é [`Qwen2.5-VL-7B-Instruct-unsloth-bnb-4bit`](https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-unsloth-bnb-4bit) ü§ó, —Å–ø–æ—Å–æ–±–Ω–æ–π –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ —Ç–µ–∫—Å—Ç.

–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Å–ª–µ–¥—É—é—â–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏:
- **OCR**: —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ (–ø–æ URL –∏–ª–∏ —Ñ–∞–π–ª—É)
- **Inference**: –æ–ø–∏—Å–∞–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–ø–æ URL –∏–ª–∏ —Ñ–∞–π–ª—É)
- **Streaming**: –ø–æ—Ç–æ–∫–æ–≤—ã–π –≤—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –æ–ø–∏—Å–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (chunked response)

---

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```text
.
‚îú‚îÄ‚îÄ app
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ api
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ v1
‚îÇ¬†¬† ‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ routes                # FastAPI endpoints
‚îÇ¬†¬† ‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ schemas               # Pydantic-—Å—Ö–µ–º—ã –∑–∞–ø—Ä–æ—Å–æ–≤ –∏ –æ—Ç–≤–µ—Ç–æ–≤
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ common                        # –û–±—â–∏–µ —É—Ç–∏–ª–∏—Ç—ã –∏ –ª–æ–≥–≥–µ—Ä—ã
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ services                      # –õ–æ–≥–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏, —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—å—é –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ main.py                       # –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ FastAPI-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ config.py                     # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
‚îú‚îÄ‚îÄ models_cache
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ Qwen2.5-VL-7B-Instruct-unsloth-bnb-4bit
‚îú‚îÄ‚îÄ poetry.lock
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ docker-compose.yml
‚îî‚îÄ‚îÄ README.md
```

---

## –ó–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ Docker

### Dockerfile

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∞–∑–æ–≤—ã–π –æ–±—Ä–∞–∑ –æ—Ç Bitnami —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å–±–æ—Ä–∫–æ–π PyTorch:

```dockerfile
FROM bitnami/pytorch:2.5.1 as production

USER root
ENV DEBIAN_FRONTEND noninteractive

WORKDIR /app

RUN apt update && apt install -y \
    curl \
    build-essential \
    gcc \
    g++ \
    clang \
    make \
    git \
    && rm -rf /var/lib/apt/lists/*

COPY ./poetry.lock ./poetry.lock
COPY ./pyproject.toml ./pyproject.toml

RUN python3 -m pip install poetry 
RUN poetry config virtualenvs.create false
RUN poetry config installer.max-workers 2
RUN poetry install --without dev --no-root

COPY . .

WORKDIR /app/app

ENTRYPOINT ["python3", "main.py"]
```

–û–±—Ä–∞–∑ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω –ø–æ–¥ `torch`, —á—Ç–æ–±—ã –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∑–∞–Ω–∏–º–∞–µ–º–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ, –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.

---

### docker-compose.yml

```yaml
version: '3.8'

services:
  qwen-vl_description:
    image: qwen-vl_description:latest
    restart: unless-stopped
    ports:
      - "8015:8015"
    env_file:
      - .env
    volumes:
      - './models_cache:/app/models_cache'
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ "2" ]
              capabilities: [gpu]
```

- **–ü–æ—Ä—Ç**: 8015
- **GPU**: —É–∫–∞–∑–∞–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ GPU (device_ids: [ "2" ])
- **Volume**: –º–æ–¥–µ–ª—å –º–æ–Ω—Ç–∏—Ä—É–µ—Ç—Å—è –∏–∑ `./models_cache`
- **–ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è**: –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –∏–∑ `.env`

---

## –ú–æ–¥–µ–ª—å

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–æ–¥–µ–ª—å:

> [Qwen2.5-VL-7B-Instruct-unsloth-bnb-4bit](https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-unsloth-bnb-4bit) ü§ó

- –ó–∞–Ω–∏–º–∞–µ—Ç ~10‚Äì11 GB –≤–∏–¥–µ–æ–ø–∞–º—è—Ç–∏ –Ω–∞ GPU
- –û–±—Ä–∞–∑ –º–æ–¥–µ–ª–∏ –≤–µ—Å–∏—Ç ~15 GB
- –†–∞–∑–º–µ—Ä –Ω–∞ –¥–∏—Å–∫–µ (–≤ `models_cache`) ‚Äî ~10 GB

---

## API

### 1. OCR

–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏:
- `POST /v1/ocr_url` ‚Äî –ø–æ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
- `POST /v1/ocr_file` ‚Äî –ø–æ –∑–∞–≥—Ä—É–∂–∞–µ–º–æ–º—É —Ñ–∞–π–ª—É

### 2. Inference

–û–ø–∏—Å–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏:
- `POST /v1/inference_url` ‚Äî –ø–æ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
- `POST /v1/inference_file` ‚Äî –ø–æ –∑–∞–≥—Ä—É–∂–∞–µ–º–æ–º—É —Ñ–∞–π–ª—É

### 3. Streaming

–ü–æ—Ç–æ–∫–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:
- `POST /v1/streaming_url` ‚Äî –ø–æ URL (—Å chunked-–æ—Ç–≤–µ—Ç–æ–º)
- `POST /v1/streaming_file` ‚Äî –ø–æ —Ñ–∞–π–ª—É (—Å chunked-–æ—Ç–≤–µ—Ç–æ–º)

---

## –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—Ç—Å—è —á–µ—Ä–µ–∑ [Poetry](https://python-poetry.org/):

```bash
poetry install --without dev --no-root
```

–î–ª—è –∑–∞–ø—É—Å–∫–∞ –≤–Ω–µ Docker:

```bash
uvicorn app.main:app --host 0.0.0.0 --port 8015
```

---

## –ü—Ä–∏–º–µ—á–∞–Ω–∏—è

- –î–ª—è –∑–∞–ø—É—Å–∫–∞ —Ç—Ä–µ–±—É–µ—Ç—Å—è **NVIDIA GPU** —Å >=12 GB –ø–∞–º—è—Ç–∏
- –í—Å–µ –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –∑–∞—Ä–∞–Ω–µ–µ –≤ `models_cache`
- –î–ª—è –ø–æ—Ç–æ–∫–æ–≤–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è `StreamingResponse`

---
